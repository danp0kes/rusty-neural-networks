{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Rusty Bargain, a used car company, is developing an app to help customers predict the market value of their own car. By using historical data on technical specifications and prices, they hope to implement a model that is accurate and time efficient.\n",
    "\n",
    "## Data Description\n",
    "\n",
    "Rusty Bargain has provided the following data:\n",
    "\n",
    "**Features**\n",
    "\n",
    "- `DateCrawled` — date profile was downloaded from the database\n",
    "- `VehicleType` - vehicle body type\n",
    "- `RegistrationYear` - vehicle registration year\n",
    "- `Gearbox` - gearbox type\n",
    "- `Power` - power (hp)\n",
    "- `Model` - vehicle model\n",
    "- `Mileage` — mileage (measured in km due to dataset's regional specifics)\n",
    "- `RegistrationMonth` - vehicle registration month\n",
    "- `FuelType` - fuel type\n",
    "- `Brand` - vehicle brand\n",
    "- `NotRepaired` - vehicle repaired or not\n",
    "- `DateCreated` - date of profile creation\n",
    "- `NumberOfPictures` - number of vehicle pictures\n",
    "- `PostalCode` - postal code of profile owner (user)\n",
    "- `LastSeen` - date of the last activity of the user\n",
    "\n",
    "**Target**\n",
    "\n",
    "- `Price` — price (Euro)\n",
    "\n",
    "## Process\n",
    "\n",
    "The process will include the following three steps:\n",
    "1. Data Preparation\n",
    "2. Model Training\n",
    "3. Model Analysis\n",
    "\n",
    "### Preparation\n",
    "\n",
    "The data will first be prepared. This will include:\n",
    "- Importing packages\n",
    "- Reading the dataframe\n",
    "- Inspecting the dataframe\n",
    "- Converting datatypes\n",
    "- Dropping unnecessary columns\n",
    "- Handling missing data\n",
    "- Encoding data\n",
    "\n",
    "### Training\n",
    "\n",
    "Training will be done on four different models:\n",
    "\n",
    "- Linear regression (1 model)\n",
    "- Random forest (1 model)\n",
    "- Gradient descent (2 models)\n",
    "\n",
    "Each will require splitting data and training according to their specific hyperparameters.\n",
    "\n",
    "### Analysis\n",
    "\n",
    "Model efficiency will be compared. This can be broken down to how accurate and how quick the model is. Accuracy will be measured with reference to the root of the mean square error (RMSE). The lower the number, the better. Each model will also be evaluated by how long each model takes along with how long the best model takes whilst iterating through hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Import relevant packages and save dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import re # to re-format column names\n",
    "from datetime import date # to calculate age\n",
    "from sklearn.model_selection import train_test_split # to split data\n",
    "from sklearn.preprocessing import OneHotEncoder # for encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder # for encoding\n",
    "import time # to calculate execution time\n",
    "from sklearn.linear_model import LinearRegression # for linear regression modelling\n",
    "from sklearn.metrics import mean_squared_error # to calculate MSE\n",
    "from sklearn.ensemble import RandomForestRegressor # for random forest modelling\n",
    "import lightgbm as lgb # for lightGBM modelling\n",
    "from catboost import CatBoostRegressor # for catboost modelling\n",
    "import time # to calculate execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/datasets/car_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lizzd/TripleTen/Sprint 12 - Numerical Methods/rusty-neural-networks/rusty-nn.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lizzd/TripleTen/Sprint%2012%20-%20Numerical%20Methods/rusty-neural-networks/rusty-nn.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m/datasets/car_data.csv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/qtconsole/lib/python3.11/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/qtconsole/lib/python3.11/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/envs/qtconsole/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_engine(f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/envs/qtconsole/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcompression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mmemory_map\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mencoding_errors\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstrict\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/qtconsole/lib/python3.11/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39mioargs\u001b[39m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[39m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/datasets/car_data.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('/datasets/car_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Columns\n",
    "\n",
    "Inspect column information to ensure column names are approriate and that columns contain the correct datatype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateCrawled</th>\n",
       "      <th>Price</th>\n",
       "      <th>VehicleType</th>\n",
       "      <th>RegistrationYear</th>\n",
       "      <th>Gearbox</th>\n",
       "      <th>Power</th>\n",
       "      <th>Model</th>\n",
       "      <th>Mileage</th>\n",
       "      <th>RegistrationMonth</th>\n",
       "      <th>FuelType</th>\n",
       "      <th>Brand</th>\n",
       "      <th>NotRepaired</th>\n",
       "      <th>DateCreated</th>\n",
       "      <th>NumberOfPictures</th>\n",
       "      <th>PostalCode</th>\n",
       "      <th>LastSeen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24/03/2016 11:52</td>\n",
       "      <td>480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>manual</td>\n",
       "      <td>0</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>0</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70435</td>\n",
       "      <td>07/04/2016 03:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24/03/2016 10:58</td>\n",
       "      <td>18300</td>\n",
       "      <td>coupe</td>\n",
       "      <td>2011</td>\n",
       "      <td>manual</td>\n",
       "      <td>190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125000</td>\n",
       "      <td>5</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>audi</td>\n",
       "      <td>yes</td>\n",
       "      <td>24/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>66954</td>\n",
       "      <td>07/04/2016 01:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/03/2016 12:52</td>\n",
       "      <td>9800</td>\n",
       "      <td>suv</td>\n",
       "      <td>2004</td>\n",
       "      <td>auto</td>\n",
       "      <td>163</td>\n",
       "      <td>grand</td>\n",
       "      <td>125000</td>\n",
       "      <td>8</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>jeep</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>90480</td>\n",
       "      <td>05/04/2016 12:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17/03/2016 16:54</td>\n",
       "      <td>1500</td>\n",
       "      <td>small</td>\n",
       "      <td>2001</td>\n",
       "      <td>manual</td>\n",
       "      <td>75</td>\n",
       "      <td>golf</td>\n",
       "      <td>150000</td>\n",
       "      <td>6</td>\n",
       "      <td>petrol</td>\n",
       "      <td>volkswagen</td>\n",
       "      <td>no</td>\n",
       "      <td>17/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>91074</td>\n",
       "      <td>17/03/2016 17:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31/03/2016 17:25</td>\n",
       "      <td>3600</td>\n",
       "      <td>small</td>\n",
       "      <td>2008</td>\n",
       "      <td>manual</td>\n",
       "      <td>69</td>\n",
       "      <td>fabia</td>\n",
       "      <td>90000</td>\n",
       "      <td>7</td>\n",
       "      <td>gasoline</td>\n",
       "      <td>skoda</td>\n",
       "      <td>no</td>\n",
       "      <td>31/03/2016 00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>60437</td>\n",
       "      <td>06/04/2016 10:17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DateCrawled  Price VehicleType  RegistrationYear Gearbox  Power  \\\n",
       "0  24/03/2016 11:52    480         NaN              1993  manual      0   \n",
       "1  24/03/2016 10:58  18300       coupe              2011  manual    190   \n",
       "2  14/03/2016 12:52   9800         suv              2004    auto    163   \n",
       "3  17/03/2016 16:54   1500       small              2001  manual     75   \n",
       "4  31/03/2016 17:25   3600       small              2008  manual     69   \n",
       "\n",
       "   Model  Mileage  RegistrationMonth  FuelType       Brand NotRepaired  \\\n",
       "0   golf   150000                  0    petrol  volkswagen         NaN   \n",
       "1    NaN   125000                  5  gasoline        audi         yes   \n",
       "2  grand   125000                  8  gasoline        jeep         NaN   \n",
       "3   golf   150000                  6    petrol  volkswagen          no   \n",
       "4  fabia    90000                  7  gasoline       skoda          no   \n",
       "\n",
       "        DateCreated  NumberOfPictures  PostalCode          LastSeen  \n",
       "0  24/03/2016 00:00                 0       70435  07/04/2016 03:16  \n",
       "1  24/03/2016 00:00                 0       66954  07/04/2016 01:46  \n",
       "2  14/03/2016 00:00                 0       90480  05/04/2016 12:47  \n",
       "3  17/03/2016 00:00                 0       91074  17/03/2016 17:40  \n",
       "4  31/03/2016 00:00                 0       60437  06/04/2016 10:17  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check head of dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Names\n",
    "\n",
    "Columns are currently in `CamelCase` which are hard to read. These will be changed to `snake_case`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change columns from CamelCase to snake_case\n",
    "df.columns = [re.sub(r'(?<!^)(?=[A-Z])', '_', col).lower() for col in df.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 354369 entries, 0 to 354368\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   date_crawled        354369 non-null  object\n",
      " 1   price               354369 non-null  int64 \n",
      " 2   vehicle_type        316879 non-null  object\n",
      " 3   registration_year   354369 non-null  int64 \n",
      " 4   gearbox             334536 non-null  object\n",
      " 5   power               354369 non-null  int64 \n",
      " 6   model               334664 non-null  object\n",
      " 7   mileage             354369 non-null  int64 \n",
      " 8   registration_month  354369 non-null  int64 \n",
      " 9   fuel_type           321474 non-null  object\n",
      " 10  brand               354369 non-null  object\n",
      " 11  not_repaired        283215 non-null  object\n",
      " 12  date_created        354369 non-null  object\n",
      " 13  number_of_pictures  354369 non-null  int64 \n",
      " 14  postal_code         354369 non-null  int64 \n",
      " 15  last_seen           354369 non-null  object\n",
      "dtypes: int64(7), object(9)\n",
      "memory usage: 43.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# check info to inspect data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save date columns to list\n",
    "date_cols = ['date_crawled', 'date_created', 'last_seen']\n",
    "\n",
    "# parse dates in correct format\n",
    "for col in date_cols:\n",
    "    df[col] = pd.to_datetime(df[col], format = '%d/%m/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find number of duplicate values \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Values\n",
    "\n",
    "For dates, integer and float columns, inspect outliers with respect to summary statistics. Compare minimum and maximum values with what is logically possible. For instace, all prices should be positive. \n",
    "\n",
    "### Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_crawled</th>\n",
       "      <th>price</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>power</th>\n",
       "      <th>mileage</th>\n",
       "      <th>registration_month</th>\n",
       "      <th>date_created</th>\n",
       "      <th>number_of_pictures</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>last_seen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>354107</td>\n",
       "      <td>354107.000000</td>\n",
       "      <td>354107.000000</td>\n",
       "      <td>354107.000000</td>\n",
       "      <td>354107.000000</td>\n",
       "      <td>354107.000000</td>\n",
       "      <td>354107</td>\n",
       "      <td>354107.0</td>\n",
       "      <td>354107.000000</td>\n",
       "      <td>354107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2016-03-21 12:56:48.735947008</td>\n",
       "      <td>4416.433287</td>\n",
       "      <td>2004.235355</td>\n",
       "      <td>110.089651</td>\n",
       "      <td>128211.811684</td>\n",
       "      <td>5.714182</td>\n",
       "      <td>2016-03-20 19:11:13.738728960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50507.145030</td>\n",
       "      <td>2016-03-29 23:51:12.374903808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016-03-05 14:06:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2014-03-10 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1067.000000</td>\n",
       "      <td>2016-03-05 14:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2016-03-13 11:52:00</td>\n",
       "      <td>1050.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>125000.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2016-03-13 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30165.000000</td>\n",
       "      <td>2016-03-23 02:50:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2016-03-21 17:50:00</td>\n",
       "      <td>2700.000000</td>\n",
       "      <td>2003.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2016-03-21 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49406.000000</td>\n",
       "      <td>2016-04-03 15:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016-03-29 14:36:00</td>\n",
       "      <td>6400.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2016-03-29 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71083.000000</td>\n",
       "      <td>2016-04-06 10:06:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016-04-07 14:36:00</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2016-04-07 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99998.000000</td>\n",
       "      <td>2016-04-07 14:58:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4514.338584</td>\n",
       "      <td>90.261168</td>\n",
       "      <td>189.914972</td>\n",
       "      <td>37906.590101</td>\n",
       "      <td>3.726682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25784.212094</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        date_crawled          price  registration_year  \\\n",
       "count                         354107  354107.000000      354107.000000   \n",
       "mean   2016-03-21 12:56:48.735947008    4416.433287        2004.235355   \n",
       "min              2016-03-05 14:06:00       0.000000        1000.000000   \n",
       "25%              2016-03-13 11:52:00    1050.000000        1999.000000   \n",
       "50%              2016-03-21 17:50:00    2700.000000        2003.000000   \n",
       "75%              2016-03-29 14:36:00    6400.000000        2008.000000   \n",
       "max              2016-04-07 14:36:00   20000.000000        9999.000000   \n",
       "std                              NaN    4514.338584          90.261168   \n",
       "\n",
       "               power        mileage  registration_month  \\\n",
       "count  354107.000000  354107.000000       354107.000000   \n",
       "mean      110.089651  128211.811684            5.714182   \n",
       "min         0.000000    5000.000000            0.000000   \n",
       "25%        69.000000  125000.000000            3.000000   \n",
       "50%       105.000000  150000.000000            6.000000   \n",
       "75%       143.000000  150000.000000            9.000000   \n",
       "max     20000.000000  150000.000000           12.000000   \n",
       "std       189.914972   37906.590101            3.726682   \n",
       "\n",
       "                        date_created  number_of_pictures    postal_code  \\\n",
       "count                         354107            354107.0  354107.000000   \n",
       "mean   2016-03-20 19:11:13.738728960                 0.0   50507.145030   \n",
       "min              2014-03-10 00:00:00                 0.0    1067.000000   \n",
       "25%              2016-03-13 00:00:00                 0.0   30165.000000   \n",
       "50%              2016-03-21 00:00:00                 0.0   49406.000000   \n",
       "75%              2016-03-29 00:00:00                 0.0   71083.000000   \n",
       "max              2016-04-07 00:00:00                 0.0   99998.000000   \n",
       "std                              NaN                 0.0   25784.212094   \n",
       "\n",
       "                           last_seen  \n",
       "count                         354107  \n",
       "mean   2016-03-29 23:51:12.374903808  \n",
       "min              2016-03-05 14:15:00  \n",
       "25%              2016-03-23 02:50:00  \n",
       "50%              2016-04-03 15:15:00  \n",
       "75%              2016-04-06 10:06:00  \n",
       "max              2016-04-07 14:58:00  \n",
       "std                              NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect summary statistics for non-categorical data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registration Year\n",
    "Registration year contains dates for cars that are registered before cars were invented or in the future from the time of the data collection. These years will be replaced with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace car registration years that are not between 1900 and 2016 with NaN\n",
    "df['registration_year'] = df['registration_year'].apply(lambda x: x if 1900 < x < 2016 else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Power\n",
    "A quick google search will reveal that the highest horse power of any car in 2016 eclipses at 1500. Cars with a horse power listed at 0 are also unlikely to be so. Values above this will be replaced with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace horse power values that are not between 1 and 2000 with 0\n",
    "df['power'] = df['power'].apply(lambda x: x if 1 < x < 1500 else np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pictures\n",
    "Every row in the dataset contains zero pictures. This column will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop picture column\n",
    "df = df.drop('number_of_pictures', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Registration Month\n",
    "\n",
    "Thirteen values have been provided (0-12) when only 12 months exist. This column will be dropped as it is not possible to distinguish where the months start and end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop registration month column\n",
    "df = df.drop('registration_month', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Crawled\n",
    "\n",
    "Now that dates have been confirmed, this column can be dropped as it has no impact on the modelling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop date_crawled column\n",
    "df = df.drop('date_crawled', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last Seen\n",
    "\n",
    "Whilst the date in which a car was last seen may indicate how much traffic the page has received, it is not useful for our analysis. We will drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop last_seen column\n",
    "df = df.drop('last_seen', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date Created\n",
    "\n",
    "Date time cannot be analysed as a continuous variable. Instead, we will extract the number of days since the ad was created and scale it accordingly. The date_created column will then be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find days since car was created\n",
    "df['age'] = (df['date_created'].max() - df['date_created'])\n",
    "\n",
    "# convert age to days\n",
    "df['age'] = df['age'].apply(lambda x: x.days)\n",
    "\n",
    "# drop date_created column\n",
    "df = df.drop('date_created', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical columns\n",
    "\n",
    "Categorical columns will be inspected for typos and inconsistencies by finding their unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vehicle_type \n",
      " ['bus' 'convertible' 'coupe' 'nan' 'other' 'sedan' 'small' 'suv' 'wagon'] \n",
      "\n",
      "gearbox \n",
      " ['auto' 'manual' 'nan'] \n",
      "\n",
      "model \n",
      " ['100' '145' '147' '156' '159' '1_reihe' '1er' '200' '2_reihe' '300c'\n",
      " '3_reihe' '3er' '4_reihe' '500' '5_reihe' '5er' '601' '6_reihe' '6er'\n",
      " '7er' '80' '850' '90' '900' '9000' '911' 'a1' 'a2' 'a3' 'a4' 'a5' 'a6'\n",
      " 'a8' 'a_klasse' 'accord' 'agila' 'alhambra' 'almera' 'altea' 'amarok'\n",
      " 'antara' 'arosa' 'astra' 'auris' 'avensis' 'aveo' 'aygo' 'b_klasse'\n",
      " 'b_max' 'beetle' 'berlingo' 'bora' 'boxster' 'bravo' 'c1' 'c2' 'c3' 'c4'\n",
      " 'c5' 'c_klasse' 'c_max' 'c_reihe' 'caddy' 'calibra' 'captiva' 'carisma'\n",
      " 'carnival' 'cayenne' 'cc' 'ceed' 'charade' 'cherokee' 'citigo' 'civic'\n",
      " 'cl' 'clio' 'clk' 'clubman' 'colt' 'combo' 'cooper' 'cordoba' 'corolla'\n",
      " 'corsa' 'cr_reihe' 'croma' 'crossfire' 'cuore' 'cx_reihe' 'defender'\n",
      " 'delta' 'discovery' 'doblo' 'ducato' 'duster' 'e_klasse' 'elefantino'\n",
      " 'eos' 'escort' 'espace' 'exeo' 'fabia' 'fiesta' 'focus' 'forester'\n",
      " 'forfour' 'fortwo' 'fox' 'freelander' 'fusion' 'g_klasse' 'galant'\n",
      " 'galaxy' 'getz' 'gl' 'glk' 'golf' 'grand' 'i3' 'i_reihe' 'ibiza'\n",
      " 'impreza' 'insignia' 'jazz' 'jetta' 'jimny' 'juke' 'justy' 'ka' 'kadett'\n",
      " 'kaefer' 'kalina' 'kalos' 'kangoo' 'kappa' 'kuga' 'laguna' 'lancer'\n",
      " 'lanos' 'legacy' 'leon' 'lodgy' 'logan' 'lupo' 'lybra' 'm_klasse'\n",
      " 'm_reihe' 'materia' 'matiz' 'megane' 'meriva' 'micra' 'mii' 'modus'\n",
      " 'mondeo' 'move' 'musa' 'mustang' 'mx_reihe' 'nan' 'navara' 'niva' 'note'\n",
      " 'nubira' 'octavia' 'omega' 'one' 'other' 'outlander' 'pajero' 'panda'\n",
      " 'passat' 'phaeton' 'picanto' 'polo' 'primera' 'ptcruiser' 'punto' 'q3'\n",
      " 'q5' 'q7' 'qashqai' 'r19' 'range_rover' 'range_rover_evoque'\n",
      " 'range_rover_sport' 'rangerover' 'rav' 'rio' 'roadster' 'roomster'\n",
      " 'rx_reihe' 's60' 's_klasse' 's_max' 's_type' 'samara' 'sandero' 'santa'\n",
      " 'scenic' 'scirocco' 'seicento' 'serie_1' 'serie_2' 'serie_3' 'sharan'\n",
      " 'signum' 'sirion' 'sl' 'slk' 'sorento' 'spark' 'spider' 'sportage'\n",
      " 'sprinter' 'stilo' 'superb' 'swift' 'terios' 'tigra' 'tiguan' 'toledo'\n",
      " 'touareg' 'touran' 'transit' 'transporter' 'tt' 'tucson' 'twingo' 'up'\n",
      " 'v40' 'v50' 'v60' 'v70' 'v_klasse' 'vectra' 'verso' 'viano' 'vito'\n",
      " 'vivaro' 'voyager' 'wrangler' 'x_reihe' 'x_trail' 'x_type' 'xc_reihe'\n",
      " 'yaris' 'yeti' 'ypsilon' 'z_reihe' 'zafira'] \n",
      "\n",
      "fuel_type \n",
      " ['cng' 'electric' 'gasoline' 'hybrid' 'lpg' 'nan' 'other' 'petrol'] \n",
      "\n",
      "brand \n",
      " ['alfa_romeo' 'audi' 'bmw' 'chevrolet' 'chrysler' 'citroen' 'dacia'\n",
      " 'daewoo' 'daihatsu' 'fiat' 'ford' 'honda' 'hyundai' 'jaguar' 'jeep' 'kia'\n",
      " 'lada' 'lancia' 'land_rover' 'mazda' 'mercedes_benz' 'mini' 'mitsubishi'\n",
      " 'nissan' 'opel' 'peugeot' 'porsche' 'renault' 'rover' 'saab' 'seat'\n",
      " 'skoda' 'smart' 'sonstige_autos' 'subaru' 'suzuki' 'toyota' 'trabant'\n",
      " 'volkswagen' 'volvo'] \n",
      "\n",
      "not_repaired \n",
      " ['nan' 'no' 'yes'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find categorical columns\n",
    "categorical = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# print unique values of categorical columns\n",
    "for col in categorical:\n",
    "    unique_values = np.sort(df[col].unique().astype(str))\n",
    "    print(col, '\\n', unique_values,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From inspection, no typos or errors were found in categorical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "Check missing data as a percentage of given data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not_repaired         20.09\n",
       "power                11.43\n",
       "vehicle_type         10.59\n",
       "fuel_type             9.29\n",
       "registration_year     6.83\n",
       "gearbox               5.60\n",
       "model                 5.56\n",
       "price                 0.00\n",
       "mileage               0.00\n",
       "brand                 0.00\n",
       "postal_code           0.00\n",
       "age                   0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find percentage of null values\n",
    "round(df.isnull().sum().sort_values(ascending = False) * 100/len(df),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Horse Power\n",
    "\n",
    "Horse power values can be filled with the average that a particular brand and model of car holds. However, models that are listed as 'other' can contain a range of different cars and will be excluded from the process.\n",
    "\n",
    "Filling will occur by concatenating brand and model columns. This is important because doing this by model only would lump all models classified as `other` as well as brands with exact models names. Those that are considered `other` will also be excluded by replacing these values with null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine brand and model columns\n",
    "df['brand_model'] = df['brand'] + '_' + df['model'].replace('other', np.nan)\n",
    "\n",
    "# groupby brand_model and find median power\n",
    "median_power = df.groupby('brand_model')['power'].median()\n",
    "\n",
    "# where power is null, replace with median power of brand_model\n",
    "df['power'] = df['power'].fillna(df['brand_model'].map(median_power))\n",
    "\n",
    "# drop brand_model column\n",
    "df = df.drop('brand_model', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Values\n",
    "\n",
    "Some missing data columns include an option for `other` already. These include:\n",
    "\n",
    "- model\n",
    "- vehicle type\n",
    "- fuel type\n",
    "\n",
    "Null values in these columns will also be set accordingly.\n",
    "\n",
    "\n",
    "\n",
    "Also fill 'not_repaired' values as `other` as these values make up a large chunk of the data that should not be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null values in columns with 'other' as an option\n",
    "df['model'] = df['model'].fillna('other')\n",
    "df['vehicle_type'] = df['vehicle_type'].fillna('other')\n",
    "df['fuel_type'] = df['fuel_type'].fillna('other')\n",
    "\n",
    "# fill null values in not_repaired column with 'other'\n",
    "df['not_repaired'] = df['not_repaired'].fillna('other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine Remaining Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "registration_year    6.83\n",
       "gearbox              5.60\n",
       "power                2.69\n",
       "price                0.00\n",
       "vehicle_type         0.00\n",
       "model                0.00\n",
       "mileage              0.00\n",
       "fuel_type            0.00\n",
       "brand                0.00\n",
       "not_repaired         0.00\n",
       "postal_code          0.00\n",
       "age                  0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find percentage of null values\n",
    "round(df.isnull().sum().sort_values(ascending = False) * 100/len(df),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop remaining null values as only a small percentage remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null values\n",
    "df = df.dropna()\n",
    "\n",
    "# reset index\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing Data\n",
    "\n",
    "### Encoding\n",
    "\n",
    "Data encoding ensures models recognise data in the appropriate way. However, different models recognise data differently. Theoretically, all could be done using OHC, but to reduce high dimensionality effects (increased training time, overfitting), each will be encoded differently for linear regression, random forest and gradient boosting models.\n",
    "\n",
    "One hot encoding is appropriate for linear regression, whereas label encoding will be more appropriate for the random forest regressor. Gradient boosting does not require encoding as they have systems inbuilt that can handle this data, however, requires datatype changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding for Linear Regression\n",
    "\n",
    "OHE assigns a new column for each unique value in categorical columns. In this case this includes values from:\n",
    "\n",
    "- `vehicle_type`\n",
    "- `gearbox`\n",
    "- `model`\n",
    "- `fuel_type`\n",
    "-`brand`\n",
    "-`not_repaired`\n",
    "\n",
    "Each will be "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308999, 315)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply one hot encoding to categorical columns\n",
    "one_hot = OneHotEncoder()\n",
    "\n",
    "# fit one hot encoder to categorical columns\n",
    "one_hot.fit(df[categorical])\n",
    "\n",
    "# transform categorical columns\n",
    "one_hot_arr = one_hot.transform(df[categorical]).toarray()\n",
    "\n",
    "# create dataframe of one hot encoded columns\n",
    "one_hot_df = pd.DataFrame(one_hot_arr, columns=one_hot.get_feature_names_out())\n",
    "\n",
    "# drop categorical columns from original dataframe\n",
    "df_ohe = df.drop(categorical, axis = 1)\n",
    "\n",
    "# left merge one hot encoded dataframe with original dataframe\n",
    "df_ohe = df_ohe.merge(one_hot_df, left_index=True, right_index=True)\n",
    "\n",
    "# confirm shape length matches original dataframe\n",
    "df_ohe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding for Random Forests\n",
    "\n",
    "Apply label encoding for categorical columns. This is done with OrdinalEncoder, but note that values are nominal.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(308999, 12)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply ordinal encoding to categorical columns\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# fit ordinal encoder to categorical columns\n",
    "data_ordinal = pd.DataFrame(encoder.fit_transform(df), columns=df.columns)\n",
    "\n",
    "#confirm shape length matches original dataframe\n",
    "data_ordinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>vehicle_type</th>\n",
       "      <th>registration_year</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>model</th>\n",
       "      <th>mileage</th>\n",
       "      <th>fuel_type</th>\n",
       "      <th>brand</th>\n",
       "      <th>not_repaired</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>236.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4879.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3479.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4596.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2502.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6967.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>650.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7007.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1264.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4193.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price  vehicle_type  registration_year  gearbox  power  model  mileage  \\\n",
       "0   236.0           3.0               64.0      1.0  103.0  116.0     12.0   \n",
       "1  3479.0           2.0               82.0      1.0  193.0  166.0     11.0   \n",
       "2  2502.0           6.0               75.0      0.0  166.0  117.0     11.0   \n",
       "3   650.0           5.0               72.0      1.0   75.0  116.0     12.0   \n",
       "4  1264.0           5.0               79.0      1.0   68.0  101.0      9.0   \n",
       "\n",
       "   fuel_type  brand  not_repaired  postal_code   age  \n",
       "0        6.0   38.0           1.0       4879.0  14.0  \n",
       "1        2.0    1.0           2.0       4596.0  14.0  \n",
       "2        2.0   14.0           1.0       6967.0  24.0  \n",
       "3        6.0   38.0           0.0       7007.0  21.0  \n",
       "4        2.0   31.0           0.0       4193.0   7.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ordinal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Changing for Gradient Boosting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 308999 entries, 0 to 308998\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count   Dtype   \n",
      "---  ------             --------------   -----   \n",
      " 0   price              308999 non-null  int64   \n",
      " 1   vehicle_type       308999 non-null  category\n",
      " 2   registration_year  308999 non-null  float64 \n",
      " 3   gearbox            308999 non-null  category\n",
      " 4   power              308999 non-null  float64 \n",
      " 5   model              308999 non-null  category\n",
      " 6   mileage            308999 non-null  int64   \n",
      " 7   fuel_type          308999 non-null  category\n",
      " 8   brand              308999 non-null  category\n",
      " 9   not_repaired       308999 non-null  category\n",
      " 10  postal_code        308999 non-null  int64   \n",
      " 11  age                308999 non-null  int64   \n",
      "dtypes: category(6), float64(2), int64(4)\n",
      "memory usage: 16.2 MB\n"
     ]
    }
   ],
   "source": [
    "# convert category columns with object type to category type\n",
    "\n",
    "# create copy of dataframe for gradient boosting as df_gb\n",
    "df_gb = df.copy()\n",
    "\n",
    "# convert category features to category type\n",
    "for feature in categorical:\n",
    "    df_gb[feature] = pd.Series(df_gb[feature], dtype=\"category\")\n",
    "    \n",
    "# show info of df_gb\n",
    "df_gb.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training\n",
    "\n",
    "Now that the data has been pre-processed, models will be trained. Functions will be made that:\n",
    "\n",
    "1. split the data into training, validation and testing.\n",
    "2. split features from targets\n",
    "\n",
    "Once done models will be trained with fine-tuned hyperparameters that will give the best result. These results will include the root of the mean of squared errors (rmse) which be used to compare the four models. The linear regression model will be tested first and used as a baseline as this model has limited hyperparameters.\n",
    "\n",
    "## Linear Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Validation and Test\n",
    "\n",
    "As no test data has been provided, data will be split into train, validation and test sets. This will occur in a 60:20:20 ratio split. To do so first split the data by 60:40 (train:validation and test). Then split the validation and test portion 50:50.\n",
    "\n",
    "### Features and Targets\n",
    "\n",
    "Within the same function, split each dataset into features and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function that splits data into sets and by features/targets\n",
    "def split_data(df):\n",
    "    # split into train, validation, and test sets\n",
    "    train, val_test = train_test_split(df, test_size = 0.4, random_state = 42)\n",
    "    val, test = train_test_split(val_test, test_size = 0.5, random_state = 42)\n",
    "    \n",
    "    # split into features and targets\n",
    "    features_train, target_train = train.drop('price', axis = 1), train['price']\n",
    "    features_val, target_val = val.drop('price', axis = 1), val['price']\n",
    "    features_test, target_test = test.drop('price', axis = 1), test['price']\n",
    "    \n",
    "    return features_train, target_train, features_val, target_val, features_test, target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data_ohe for linear regression\n",
    "features_train_ohe, target_train_ohe, features_val_ohe, \\\n",
    "target_val_ohe, features_test_ohe, target_test_ohe = split_data(df_ohe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Predictions and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2665.65\n",
      "Execution time: 5.09\n"
     ]
    }
   ],
   "source": [
    "# start time\n",
    "start_time = time.time()  # Record start time\n",
    "\n",
    "# train the model\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit the model\n",
    "model.fit(features_train_ohe, target_train_ohe)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(features_val_ohe)\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = mean_squared_error(target_val_ohe, predictions) ** 0.5\n",
    "\n",
    "# print RMSE\n",
    "print('RMSE:', round(rmse,2))\n",
    "\n",
    "# end time\n",
    "end_time = time.time()  \n",
    "\n",
    "# calculate execution time\n",
    "execution_time = end_time - start_time  # Calculate execution time\n",
    "\n",
    "# print execution time\n",
    "print('Execution time:', round(execution_time,2),'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor\n",
    "\n",
    "The random forest regressor will follow a similar process. Key differences will include using the label encoded dataframe and using more hyperparameters to find a more optimal RMSE value. Hyperparameters will be looped based on tree depth and number of estimators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data_ordinal for linear regression\n",
    "features_train_ordinal, target_train_ordinal, features_val_ordinal, \\\n",
    "target_val_ordinal, features_test_ordinal, target_test_ordinal = split_data(data_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators: 70\n",
      "max_depth: 12\n",
      "RMSE: 363.77\n",
      "Time to calculate best parameters: 23.39\n",
      "Totatl execution time: 404.45\n"
     ]
    }
   ],
   "source": [
    " # Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# set hyperparameters\n",
    "n_estimators = range(30, 71, 10)\n",
    "max_depth = range(7, 13, 1)\n",
    "\n",
    "# best rmse score (set high to start)\n",
    "best_rmse = 10000\n",
    "\n",
    "# loop through hyperparameters\n",
    "for n in n_estimators:\n",
    "    for d in max_depth:\n",
    "        # loop start time\n",
    "        loop_time_start = time.time()\n",
    "        \n",
    "        # train the model\n",
    "        model = RandomForestRegressor(random_state=42, n_estimators=n, max_depth=d)\n",
    "\n",
    "        # fit the model\n",
    "        model.fit(features_train_ordinal, target_train_ordinal)\n",
    "\n",
    "        # make predictions\n",
    "        predictions = model.predict(features_val_ordinal)\n",
    "\n",
    "        # calculate RMSE\n",
    "        rmse = mean_squared_error(target_val_ordinal, predictions) ** 0.5\n",
    "\n",
    "        # if rmse is lower than best_rmse, update best_rmse\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_n = n\n",
    "            best_d = d\n",
    "            best_time = time.time() - loop_time_start\n",
    "\n",
    "# end time\n",
    "end_time = time.time()\n",
    "\n",
    "# calculate execution time\n",
    "execution_time = end_time - start_time  # Calculate total execution time\n",
    "            \n",
    "# print best hyperparameters\n",
    "print('n_estimators:', best_n)\n",
    "print('max_depth:', best_d)\n",
    "print('RMSE:', round(best_rmse,2))\n",
    "print('Time to calculate best parameters:', round(best_time,2))\n",
    "print('Totatl execution time:', round(execution_time,2), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting\n",
    "\n",
    "Gradient boosting will use LightGBM and CatBoost models. Both will use the same data which will be split from the `df_gb` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "features_train_gb, target_train_gb, features_val_gb, \\\n",
    "target_val_gb, features_test_gb, target_test_gb = split_data(df_gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Light GBM\n",
    "\n",
    "Hyperparameters that will be looped over include number of leaves, tree depth and learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1586.68\n",
      "Best hyperparameters: {'num_leaves': 80, 'max_depth': 10, 'learning_rate': 0.1}\n",
      "Execution time: 777.14 seconds\n"
     ]
    }
   ],
   "source": [
    "# Set high RMSE to start\n",
    "best_rmse = 10000\n",
    "\n",
    "# Set best hyperparameters\n",
    "best_params = {'num_leaves': None, 'max_depth': None, 'learning_rate': None}\n",
    "\n",
    "# Set hyperparameters\n",
    "n_leaves = range(50, 91, 10)\n",
    "depth = range(7, 13, 1)\n",
    "learning_rate = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Loop through hyperparameters\n",
    "for num_leaves in n_leaves:\n",
    "    for max_depth in depth:\n",
    "        for lr in learning_rate:\n",
    "            # Define parameters\n",
    "            params = {\n",
    "                'task': 'train', \n",
    "                'boosting': 'gbdt',\n",
    "                'objective': 'regression',\n",
    "                'num_leaves': num_leaves,\n",
    "                'max_depth': max_depth,\n",
    "                'verbose': -1,\n",
    "                'metric': 'rmse',\n",
    "                'learning_rate': lr,\n",
    "            }\n",
    "\n",
    "            # Load data into LightGBM dataset\n",
    "            lgb_train = lgb.Dataset(features_train_gb, target_train_gb)\n",
    "\n",
    "            # Fit the model\n",
    "            model = lgb.train(params, lgb_train, num_boost_round=1000)\n",
    "\n",
    "            # Make predictions\n",
    "            predictions = model.predict(features_val_gb, num_iteration=model.best_iteration)\n",
    "\n",
    "            # Calculate RMSE\n",
    "            rmse = mean_squared_error(target_val_gb, predictions) ** 0.5\n",
    "\n",
    "            # If RMSE is lower than best_rmse, update best_rmse and best_params\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_params['num_leaves'] = num_leaves\n",
    "                best_params['max_depth'] = max_depth\n",
    "                best_params['learning_rate'] = lr\n",
    "                best_time = time.time() - start_time\n",
    "\n",
    "# Print best hyperparameters\n",
    "print('RMSE:', round(best_rmse, 2))\n",
    "print('Best hyperparameters:', best_params)\n",
    "print('Time to calculate best parameters:', round(best_time, 2), 'seconds')\n",
    "print('Total execution time:', round(time.time() - start_time, 2), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.24868\n",
      "0:\tlearn: 3867.3992240\ttotal: 106ms\tremaining: 31.7s\n",
      "20:\tlearn: 1899.0404320\ttotal: 932ms\tremaining: 12.4s\n",
      "40:\tlearn: 1814.0047265\ttotal: 1.66s\tremaining: 10.5s\n",
      "60:\tlearn: 1763.4937535\ttotal: 2.35s\tremaining: 9.2s\n",
      "80:\tlearn: 1734.8414802\ttotal: 3.2s\tremaining: 8.65s\n",
      "100:\tlearn: 1714.7022312\ttotal: 3.95s\tremaining: 7.78s\n",
      "120:\tlearn: 1699.4839566\ttotal: 4.66s\tremaining: 6.9s\n",
      "140:\tlearn: 1686.5864089\ttotal: 5.58s\tremaining: 6.29s\n",
      "160:\tlearn: 1673.1592576\ttotal: 6.29s\tremaining: 5.43s\n",
      "180:\tlearn: 1661.5575040\ttotal: 7.06s\tremaining: 4.64s\n",
      "200:\tlearn: 1650.3172890\ttotal: 7.69s\tremaining: 3.79s\n",
      "220:\tlearn: 1643.1304999\ttotal: 8.47s\tremaining: 3.03s\n",
      "240:\tlearn: 1634.5835119\ttotal: 9.23s\tremaining: 2.26s\n",
      "260:\tlearn: 1626.9940590\ttotal: 10s\tremaining: 1.5s\n",
      "280:\tlearn: 1619.6881842\ttotal: 10.7s\tremaining: 727ms\n",
      "299:\tlearn: 1612.7646550\ttotal: 11.6s\tremaining: 0us\n",
      "RMSE: 1660.48\n",
      "Execution time: 11.94 seconds\n"
     ]
    }
   ],
   "source": [
    "# record start time\n",
    "start_time = time.time() \n",
    "\n",
    "# initialize CatBoostRegressor with appropriate parameters\n",
    "model = CatBoostRegressor(loss_function='RMSE', iterations=300, random_seed=42)\n",
    "\n",
    "# create list of categorical features\n",
    "cat_features = ['vehicle_type', 'gearbox', 'model', 'fuel_type', 'brand', 'not_repaired']\n",
    "\n",
    "# fit the model\n",
    "model.fit(features_train_gb, target_train_gb, cat_features=cat_features, verbose=20)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(features_val_gb)\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = mean_squared_error(target_val_gb, predictions) ** 0.5\n",
    "\n",
    "# print RMSE\n",
    "print('RMSE:', round(rmse, 2))\n",
    "\n",
    "# record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# calculate execution time\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# print execution time\n",
    "print('Execution time:', round(execution_time, 2), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "Linear regression shows a large RMSE value at 2666 that was calculated in just over 5 seconds. This indicates that this model may not be that accurate, however, acts as a baseline for the other models.\n",
    "\n",
    "\n",
    "## Random Forest\n",
    "The random forest model was tested next and provided a much better RMSE value at around 364. However, iterating through these hyperparameters took almost 7 minutes to find the best model. This model itself took just over 23 seconds to train, fit and predict.\n",
    "\n",
    "## Gradient Descent \n",
    "The light GBM performed worst by only producing an RMSE value of 1587, but took almost 13 minutes to compute. This is compared to the CatBoost model which provided a worse RMSE of 1660 in a 12 second period.\n",
    "\n",
    "## Conclusion\n",
    "Overall, the random forest model provided the best results. Whilst it is a little slower than the linear regression and CatBoost models, its accuracy is unmatched.\n",
    "\n",
    "## Final Predictions\n",
    "Now that this model has been chosen, predictions will be made on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 369.27\n",
      "Execution time: 22.91 seconds\n"
     ]
    }
   ],
   "source": [
    "# record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# set model to best hyperparameters\n",
    "model = RandomForestRegressor(random_state=42, n_estimators=70, max_depth=12)\n",
    "\n",
    "# fit the model\n",
    "model.fit(features_train_ordinal, target_train_ordinal)\n",
    "\n",
    "# make predictions\n",
    "predictions = model.predict(features_test_ordinal)\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = mean_squared_error(target_test_ordinal, predictions) ** 0.5\n",
    "\n",
    "# record end time\n",
    "end_time = time.time()\n",
    "\n",
    "# calculate execution time\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# print RMSE and execution time\n",
    "print('RMSE:', round(rmse, 2))\n",
    "print('Execution time:', round(execution_time, 2), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "The RMSE value is similar to the RMSE value of the validation set. The execution time is also reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Rusty Bargain provided used car model data to create a prediction model. This data was prepared and trained. The best model was the random forest model that provided a significantly lower RMSE than all other models whilst only taking 20 seconds longer. This model was tested on the test data and provided similar results to the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checklist\n",
    "\n",
    "Type 'x' to check. Then press Shift+Enter.\n",
    "\n",
    "- [x]  Jupyter Notebook is open\n",
    "- [x]  Code is error free\n",
    "- [x]  The cells with the code have been arranged in order of execution\n",
    "- [x]  The data has been downloaded and prepared\n",
    "- [x]  The models have been trained\n",
    "- [x]  The analysis of speed and quality of the models has been performed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qtconsole",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
